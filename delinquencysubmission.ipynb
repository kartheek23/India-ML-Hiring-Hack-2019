{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import numpy as np\n",
    "parDir = os.path.normpath(os.getcwd() + os.sep + os.pardir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Please make sure you have the train and test csv files in /input/india-ml-hiring-av directory of your os. In case if you have them else where please change the code below****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(parDir + \"/input/india-ml-hiring-av/train.csv\")\n",
    "test = pd.read_csv(parDir+ \"/input/india-ml-hiring-av/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Categorical Features are listed below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['source','financial_institution','origination_date','first_payment_date',\n",
    "                   'loan_purpose']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Numerical Features are listed below**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_scale = ['co-borrower_credit_score','borrower_credit_score','debt_to_income_ratio',\n",
    "                  'loan_term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below function takes a dataframe and columns as input and label encodes them.\n",
    "def encodeCategoricals(df,columns):\n",
    "    # apply le on categorical feature columns\n",
    "    df[columns] = df[columns].apply(lambda col: LabelEncoder().fit_transform(col))\n",
    "    return df\n",
    "#The below function takes a dataframe and columns as input and scales them using standard scaler\n",
    "def scaleNumericVariables(df,columns):\n",
    "    sc = StandardScaler()\n",
    "    new_data = pd.DataFrame(np.round(sc.fit_transform(df[values_to_scale]),3),\n",
    "                            columns = columns)\n",
    "    df[columns] = new_data[columns]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please transform the variables into the required variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = encodeCategoricals(train,categorical_cols)\n",
    "train = scaleNumericVariables(train,values_to_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the corelation of the variables to perform feature removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.003 loan_id\n",
      "0.008 source\n",
      "-0.002 financial_institution\n",
      "0.054 interest_rate\n",
      "-0.017 unpaid_principal_bal\n",
      "0.024 loan_term\n",
      "-0.011 origination_date\n",
      "-0.012 first_payment_date\n",
      "0.016 loan_to_value\n",
      "-0.040 number_of_borrowers\n",
      "0.038 debt_to_income_ratio\n",
      "-0.094 borrower_credit_score\n",
      "0.023 loan_purpose\n",
      "0.006 insurance_percent\n",
      "-0.043 co-borrower_credit_score\n",
      "0.006 insurance_type\n",
      "0.092 m1\n",
      "0.147 m2\n",
      "0.157 m3\n",
      "0.219 m4\n",
      "0.260 m5\n",
      "0.288 m6\n",
      "0.309 m7\n",
      "0.339 m8\n",
      "0.369 m9\n",
      "0.368 m10\n",
      "0.410 m11\n",
      "0.466 m12\n",
      "1.000 m13\n"
     ]
    }
   ],
   "source": [
    "for col in train.columns:\n",
    "    corr, _ = pearsonr(train[col], train['m13'])\n",
    "    print('%.3f' % corr,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The final variables that are used in the model are listed below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_to_use = ['m1','m2','m3','m4','m5','m6','m7','m8','m9','m10','m11','m12',\n",
    "             'co-borrower_credit_score','borrower_credit_score','loan_purpose',\n",
    "             'debt_to_income_ratio','number_of_borrowers','loan_term']\n",
    "\n",
    "target= ['m13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final variables dataframe\n",
    "train = train[fea_to_use+target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(train[fea_to_use],train[target],\n",
    "                                       test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a custom metric for scoring the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xg_f1(y,t):\n",
    "    t = t.get_label()\n",
    "    y_bin = [1. if y_cont > 0.5 else 0. for y_cont in y] # binaryzing your output\n",
    "    return 'f1',f1_score(t,y_bin,average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The below parameters have been fine tuned to give optimal performance on Test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.7s finished\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:04:55] INFO: /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[0]\tvalidation_0-error:0.008272\tvalidation_0-f1:0.388535\n",
      "[17:04:55] INFO: /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[1]\tvalidation_0-error:0.007324\tvalidation_0-f1:0.401408\n",
      "[17:04:56] INFO: /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[2]\tvalidation_0-error:0.00517\tvalidation_0-f1:0.473684\n",
      "[17:04:56] INFO: /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 128 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[3]\tvalidation_0-error:0.005342\tvalidation_0-f1:0.504\n",
      "[17:04:56] INFO: /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[4]\tvalidation_0-error:0.00461\tvalidation_0-f1:0.532751\n",
      "[17:04:56] INFO: /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 142 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[5]\tvalidation_0-error:0.004739\tvalidation_0-f1:0.521739\n",
      "[17:04:56] INFO: /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[6]\tvalidation_0-error:0.004782\tvalidation_0-f1:0.523605\n",
      "[17:04:56] INFO: /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[7]\tvalidation_0-error:0.00504\tvalidation_0-f1:0.506329\n",
      "[17:04:56] INFO: /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[8]\tvalidation_0-error:0.004696\tvalidation_0-f1:0.532189\n",
      "[17:04:56] INFO: /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[9]\tvalidation_0-error:0.004653\tvalidation_0-f1:0.530435\n",
      "[17:04:56] INFO: /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 166 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[10]\tvalidation_0-error:0.004351\tvalidation_0-f1:0.551111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=0.4, gamma=0,\n",
       "                                     learning_rate=1e-05, max_delta_step=0,\n",
       "                                     max_depth=9, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=11, n_jobs=-1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=30, seed=27, silent=None,\n",
       "                                     subsample=0.4, verbosity=2),\n",
       "             iid=False, n_jobs=-1, param_grid={}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    \n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.00001, n_estimators=11, max_depth=9,\n",
    " subsample=0.4, colsample_bytree=0.4,\n",
    " objective= 'binary:logistic', n_jobs=-1, scale_pos_weight=30,seed=27,verbosity=2), \n",
    " param_grid = param_test1,n_jobs=-1,iid=False, cv=5,verbose=3)\n",
    "gsearch1.fit(X_train,y_train,verbose=True,eval_set=[(X_test,y_test)],eval_metric=xg_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform the same preprocessing steps on test data as the train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = encodeCategoricals(test,categorical_cols)\n",
    "test_data = scaleNumericVariables(test,values_to_scale)\n",
    "test_data = test_data[fea_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict on Test Set and submit final data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "preds_valid = pd.DataFrame(gsearch1.predict(test_data),columns=target)\n",
    "preds_valid['loan_id'] = test['loan_id']\n",
    "preds_valid = preds_valid[['loan_id', 'm13']]\n",
    "preds_valid.to_csv(\"sample_submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
